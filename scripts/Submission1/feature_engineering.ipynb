{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import cPickle as pickle\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_numerical_features(df):\n",
    "    df['num_photos'] = df['photos'].apply(len) # how many photos a listing has\n",
    "    df['num_features'] = df['features'].apply(len) # number of features listed\n",
    "    df['num_description'] = df['description'].apply(lambda x: len(x.split(\" \"))) # description length\n",
    "    df[\"created\"] = pd.to_datetime(df[\"created\"])\n",
    "    df[\"created_year\"] = df[\"created\"].dt.year\n",
    "    df[\"created_month\"] = df[\"created\"].dt.month\n",
    "    df[\"created_day\"] = df[\"created\"].dt.day\n",
    "    df[\"created_day_of_week\"] = df[\"created\"].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_categorical_features(df):\n",
    "    le = LabelEncoder()\n",
    "\n",
    "    df.building_id = le.fit_transform(df.building_id)\n",
    "    df.manager_id = le.fit_transform(df.manager_id)\n",
    "    \n",
    "    # test set will not have a column for interest level\n",
    "    try:\n",
    "         # used different method to encode interest level to preserve increasing order\n",
    "        target_num = {'low':0, 'medium':1, 'high':2}\n",
    "        df.interest_level = df.interest_level.apply(lambda x: target_num[x])\n",
    "    except AttributeError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_text_features(df, type):\n",
    "    # df : pandas dataframe\n",
    "    # type : string, either test or train depending on which file it is\n",
    "\n",
    "    # Features column\n",
    "\n",
    "    df['features'] = df['features'].apply(lambda x: \" \".join(x)) # combine list to a string\n",
    "\n",
    "    stop = stopwords.words('english') # remove stopwords\n",
    "    vect = CountVectorizer(stop_words=stop, max_features=200)\n",
    "    features_dtm = vect.fit_transform(df['features'])\n",
    "\n",
    "    with open('../processed/' + type +'_features_dtm.dat','wb') as outfile:\n",
    "        pickle.dump(features_dtm, outfile, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    ###########################################################################\n",
    "    # Description column\n",
    "    vect2 = CountVectorizer(stop_words=stop, max_features=200)\n",
    "    description_dtm = vect2.fit_transform(df['description'])\n",
    "\n",
    "    with open('../processed/' + type +'_description_dtm.dat','wb') as outfile:\n",
    "        pickle.dump(description_dtm, outfile, pickle.HIGHEST_PROTOCOL)\t\n",
    "\n",
    "    ###########################################################################\n",
    "    # Display address column\n",
    "    vect3 = CountVectorizer(stop_words=stop, max_features=200)\n",
    "    display_address_dtm = vect3.fit_transform(df['display_address'])\n",
    "\n",
    "    with open('../processed/' + type +'_display_address_dtm.dat','wb') as outfile:\n",
    "        pickle.dump(display_address_dtm, outfile, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_json('../data/train.json')\n",
    "create_numerical_features(train)\n",
    "create_categorical_features(train)\n",
    "create_text_features(train,'train')\n",
    "\n",
    "test = pd.read_json('../data/test.json')\n",
    "create_numerical_features(test)\n",
    "create_categorical_features(test)\n",
    "create_text_features(test,'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_features = ['bathrooms', 'bedrooms',\n",
    "            'latitude', 'longitude',\n",
    "            'price', 'num_photos',\n",
    "            'num_features', 'num_description',\n",
    "           'interest_level','building_id',\n",
    "            'created_year','created_month',\n",
    "            'created_day', 'manager_id',\n",
    "           'created_day_of_week']\n",
    "\n",
    "test_features = copy.copy(train_features) # make copy of feature list\n",
    "test_features.remove('interest_level') # remove interest level as test set won't have this column\n",
    "\n",
    "train = train.set_index(train.listing_id) # set listing id to be index\n",
    "train = train[train_features] # trim off unwanted columns\n",
    "\n",
    "test = test.set_index(test.listing_id) # set listing id to be index\n",
    "test = test[test_features] # trim off unwantd columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.to_csv('../processed/train_processed.csv')\n",
    "test.to_csv('../processed/test_processed.csv')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
